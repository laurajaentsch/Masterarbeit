{
 "cells": [
  {
   "cell_type": "code",
   "id": "9ee026007b7ed3d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:16:00.855228Z",
     "start_time": "2025-05-09T07:16:00.852551Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-05-09T07:16:00.875826Z",
     "start_time": "2025-05-09T07:16:00.872492Z"
    }
   },
   "source": [
    "EXERCISE = 4\n",
    "\n",
    "\n",
    "def load_data(catched: bool):\n",
    "    df = pd.read_csv(f'./data/Exercise_{EXERCISE}_valid_catched_{catched}.csv')\n",
    "    df.ID = df.ID.astype(int)\n",
    "    df.TrialInfo = df.TrialInfo.astype(int)\n",
    "    df.Distance = df.Distance.astype(float)\n",
    "    df.Catch = df.Catch.replace({True: 1, False: 0}).astype(int)\n",
    "    df.Group = df.Group.replace({\"RL 7e\": \"RL\", \"RL 7f\": \"RL\", \"kontrollgruppe\": \"Kontrollgruppe\"})\n",
    "\n",
    "    # Load gender data: ID, gender\n",
    "    df_gender = pd.read_csv(\"data/gender.csv\")\n",
    "    # add gender to the df\n",
    "    df = pd.merge(df, df_gender, on=\"ID\", how=\"left\")\n",
    "\n",
    "    df_mean = df.groupby([\"ID\", \"TrialInfo\"]).agg(\n",
    "        Mean_Distance=(\"Distance\", \"mean\"),\n",
    "        Mean_Catch=(\"Catch\", \"mean\"),\n",
    "        Group=(\"Group\", \"first\"),\n",
    "        Gender=(\"Gender\", \"first\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    #sort by ID and TrialInfo\n",
    "    df_mean = df_mean.sort_values(by=[\"ID\", \"TrialInfo\", \"Gender\"])\n",
    "    # Only keep TrialInfo 1 and 4\n",
    "    df_filtered = df_mean[df_mean['TrialInfo'].isin([1, 4])]\n",
    "    return df_filtered\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "7874b92a222bf493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:16:01.224061Z",
     "start_time": "2025-05-09T07:16:00.889260Z"
    }
   },
   "source": [
    "import json\n",
    "from scipy import stats\n",
    "\n",
    "results = {}\n",
    "\n",
    "objectives = [\"Mean_Distance\", \"Mean_Catch\"]\n",
    "for objective in objectives:\n",
    "\n",
    "    if objective == \"Mean_Distance\":\n",
    "        df_filtered = load_data(catched=True)\n",
    "    else:\n",
    "        df_filtered = load_data(catched=False)\n",
    "\n",
    "    # Pivot to wide format: one row = one student\n",
    "    df_pivot = df_filtered.pivot_table(index=['ID', 'Group', \"Gender\"],\n",
    "                                       columns='TrialInfo',\n",
    "                                       values=objective).reset_index()\n",
    "\n",
    "    # Rename columns. for easier handling\n",
    "    df_pivot = df_pivot.rename(columns={1: 'Week1', 4: 'Week4'})\n",
    "\n",
    "    genders = df_pivot[\"Gender\"].unique()\n",
    "    groups = df_pivot[\"Group\"].unique()\n",
    "\n",
    "    for group in groups:\n",
    "        # Subset the group\n",
    "        group_data = df_pivot[df_pivot['Group'] == group]\n",
    "\n",
    "        week1 = group_data['Week1']\n",
    "        week4 = group_data['Week4']\n",
    "\n",
    "        # Check normality of the differences\n",
    "        stat, p_normality = stats.shapiro(week1 - week4)\n",
    "\n",
    "        if p_normality > 0.05:\n",
    "            # Differences are normal --> Paired t-test\n",
    "            t_stat, p_value = stats.ttest_rel(week1, week4)\n",
    "            test_used = 'Paired t-test'\n",
    "        else:\n",
    "            # Differences are not normal --> Wilcoxon signed-rank test\n",
    "            w_stat, p_value = stats.wilcoxon(week1, week4)\n",
    "            test_used = 'Wilcoxon signed-rank'\n",
    "\n",
    "        # Determine if significant\n",
    "        significant = bool(p_value < 0.05)\n",
    "\n",
    "        # Save results\n",
    "        print(group)\n",
    "        results[f\"{group}-{objective}\"] = {\n",
    "            'test': test_used,\n",
    "            'p_value': float(p_value),\n",
    "            'significant': significant,\n",
    "            \"p-normality\": float(p_normality),\n",
    "            \"gender\": \"gesamt\",\n",
    "            \"size\": len(week1),\n",
    "            \"objective\": objective\n",
    "        }\n",
    "\n",
    "        for gender in genders:\n",
    "            gender_data = group_data[group_data[\"Gender\"] == gender]\n",
    "            week1 = gender_data['Week1']\n",
    "            week4 = gender_data['Week4']\n",
    "\n",
    "            print(f\"{group}-{gender}-{len(week1)}\")\n",
    "\n",
    "            stat, p_normality = stats.shapiro(week1 - week4)\n",
    "\n",
    "            if p_normality > 0.05:\n",
    "                t_stat, p_value = stats.ttest_rel(week1, week4)\n",
    "                test_used = 'Paired t-test'\n",
    "            else:\n",
    "                w_stat, p_value = stats.wilcoxon(week1, week4)\n",
    "                test_used = 'Wilcoxon signed-rank'\n",
    "\n",
    "            significant = bool(p_value < 0.05)\n",
    "\n",
    "            results[f\"{group}-{gender}-{objective}\"] = {\n",
    "                'test': test_used,\n",
    "                'p_value': float(p_value),\n",
    "                'significant': significant,\n",
    "                \"p-normality\": float(p_normality),\n",
    "                \"gender\": gender,\n",
    "                \"size\": len(week1),\n",
    "                \"objective\": objective\n",
    "            }\n",
    "\n",
    "# Save results to JSON\n",
    "with open(f'./results/significancy_{EXERCISE}.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VR\n",
      "VR-m-2\n",
      "VR-w-0\n",
      "RL\n",
      "RL-m-17\n",
      "RL-w-11\n",
      "Kontrollgruppe\n",
      "Kontrollgruppe-m-6\n",
      "Kontrollgruppe-w-0\n",
      "VR\n",
      "VR-w-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/_sqg2_l97_541t3dyx02t65w0000gn/T/ipykernel_65866/1437825930.py:33: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_normality = stats.shapiro(week1 - week4)\n",
      "/var/folders/50/_sqg2_l97_541t3dyx02t65w0000gn/T/ipykernel_65866/1437825930.py:66: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stat, p_normality = stats.shapiro(week1 - week4)\n",
      "/Users/janlemcke/Repos/Masterarbeit/.venv/lib/python3.11/site-packages/scipy/_lib/_util.py:1023: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  return fun(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VR-m-16\n",
      "RL\n",
      "RL-w-22\n",
      "RL-m-25\n",
      "Kontrollgruppe\n",
      "Kontrollgruppe-w-4\n",
      "Kontrollgruppe-m-7\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "6a150116873b8d9",
   "metadata": {},
   "source": [
    "# Step 3: Across all groups"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a4f018269b7f681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:16:01.241539Z",
     "start_time": "2025-05-09T07:16:01.236910Z"
    }
   },
   "source": [
    "# Pivot to wide format: one row = one student\n",
    "df_pivot = df_mean.pivot_table(index=['ID', 'Group'],\n",
    "                               columns='TrialInfo',\n",
    "                               values='Mean_Distance').reset_index()\n",
    "\n",
    "# Rename columns for easier handling\n",
    "df_pivot = df_pivot.rename(columns={1: \"Week1\", 2: \"Week2\", 3: \"Week3\", 4: 'Week4'})\n",
    "\n",
    "print(df_pivot)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrialInfo   ID           Group     Week1     Week2     Week3     Week4\n",
      "0            8              VR  0.053097  0.055863  0.036504  0.309735\n",
      "1           16              VR  0.088496  0.172566  0.164159  0.088274\n",
      "2           61              RL  0.136816  0.000000  0.074627  0.093284\n",
      "3           62              RL  0.059701  0.039801  0.039801  0.013930\n",
      "4           63              RL  0.000000  0.116086  0.215589  0.075871\n",
      "5           64              RL  0.124378  0.248756  0.149254  0.005970\n",
      "6           66              RL  0.031509  0.009950  0.148259  0.055721\n",
      "7           69              RL  0.331675  0.132670  0.268657  0.058043\n",
      "8           70              RL  0.569154  0.131841  0.023632  0.009950\n",
      "9           72              RL  0.290216  0.149254  0.149254  0.072968\n",
      "10          74              RL  0.000000  0.009950  0.014925  0.000000\n",
      "11          77              RL  0.016169  0.012438  0.004975  0.001990\n",
      "12          78              RL  0.000995  0.000000  0.000000  0.000000\n",
      "13          81              RL  0.223881  0.049751  0.029851  0.021891\n",
      "14          86              RL  0.016584  0.019900  0.024876  0.019900\n",
      "15          91              RL  0.376451  0.297264  0.019900  0.026866\n",
      "16          92              RL  0.000000  0.007463  0.037313  0.000000\n",
      "17         103              RL  0.272500  0.306250  0.236250  0.220000\n",
      "18         104              RL  0.137500  0.030000  0.025000  0.000000\n",
      "19         105              RL  0.075000  0.158333  0.125000  0.025000\n",
      "20         109              RL  0.250000  0.150000  0.100000  0.020000\n",
      "21         110              RL  0.060000  0.030000  0.026000  0.020000\n",
      "22         111              RL  0.362500  0.300000  0.225000  0.180000\n",
      "23         112              RL  0.730000  0.387500  0.310000  0.310000\n",
      "24         113              RL  0.337500  0.045000  0.190000  0.005000\n",
      "25         114              RL  0.350000  0.216667  0.233333  0.100000\n",
      "26         115              RL  0.190000  0.210000  0.185000  0.120000\n",
      "27         116              RL  0.375000  0.270000  0.190000  0.150000\n",
      "28         119              RL  0.395000  0.360000  0.360000  0.250000\n",
      "29         122              RL  0.925000  0.383333  0.300000  0.583333\n",
      "30         127  Kontrollgruppe  0.065000  0.075000  0.135000  0.040000\n",
      "31         133  Kontrollgruppe  0.085000  0.050000  0.050000  0.037500\n",
      "32         134  Kontrollgruppe  0.050000  0.040000  0.052000  0.150000\n",
      "33         135  Kontrollgruppe  0.450000  0.150000  0.050000  0.750000\n",
      "34         138  Kontrollgruppe  0.225000  0.025000  0.025000  0.050000\n",
      "35         144  Kontrollgruppe  0.150000  0.075000  0.066667  0.050000\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "6fd0bd0b4edb1331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:16:01.333922Z",
     "start_time": "2025-05-09T07:16:01.254677Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define X once, same for all\n",
    "X = np.array([1, 2, 3, 4]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Function to calculate slope for one student\n",
    "def calculate_slope(row):\n",
    "    y = np.array([row['Week1'], row['Week2'], row['Week3'], row['Week4']])\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    return model.coef_[0]  # coef_ returns an array, take first element (slope)\n",
    "\n",
    "\n",
    "# Apply to each row\n",
    "df_pivot['Slope'] = df_pivot.apply(calculate_slope, axis=1)\n",
    "\n",
    "# Add metrics\n",
    "df_pivot['Improvement_%'] = (df_pivot['Week4'] - df_pivot['Week1']) / df_pivot['Week1'] * 100\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlinear_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LinearRegression\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# Define X once, same for all\u001B[39;00m\n\u001B[32m      4\u001B[39m X = np.array([\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m, \u001B[32m3\u001B[39m, \u001B[32m4\u001B[39m]).reshape(-\u001B[32m1\u001B[39m, \u001B[32m1\u001B[39m)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'sklearn'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:16:01.339323Z",
     "start_time": "2025-04-27T13:25:39.719885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Define all pairs you want to compare\n",
    "group_pairs = [('VR', 'Kontrollgruppe'), ('RL', 'Kontrollgruppe'), ('VR', 'RL')]\n",
    "\n",
    "# Metrics to analyze\n",
    "metrics = ['Improvement_%', 'Slope']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\n\\n--- Analyzing {metric} ---\")\n",
    "    results[metric] = {}\n",
    "\n",
    "    for group1, group2 in group_pairs:\n",
    "        data1 = df_pivot[df_pivot['Group'] == group1][metric]\n",
    "        data2 = df_pivot[df_pivot['Group'] == group2][metric]\n",
    "\n",
    "        # Check normality for both groups\n",
    "        p_norm1 = stats.shapiro(data1)[1]\n",
    "        p_norm2 = stats.shapiro(data2)[1]\n",
    "\n",
    "        normal = (p_norm1 > 0.05) and (p_norm2 > 0.05)\n",
    "\n",
    "        if normal:\n",
    "            # Use independent t-test\n",
    "            stat, p_value = stats.ttest_ind(data1, data2)\n",
    "            test_used = 'Independent t-test'\n",
    "        else:\n",
    "            # Use Mann-Whitney U test\n",
    "            stat, p_value = stats.mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "            test_used = 'Mann-Whitney U'\n",
    "\n",
    "        # Save results\n",
    "        results[metric][(group1, group2)] = {\n",
    "            'test': test_used,\n",
    "            'p_value': p_value\n",
    "        }\n",
    "\n",
    "        # Print results\n",
    "        print(f\"\\n{group1} vs {group2}\")\n",
    "        print(f\"Test used: {test_used}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"✅ Significant difference!\")\n",
    "        else:\n",
    "            print(\"❌ No significant difference.\")\n"
   ],
   "id": "6bc91aa2c6ad584e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Analyzing Improvement_% ---\n",
      "\n",
      "VR vs Kontrollgruppe\n",
      "Test used: Mann-Whitney U\n",
      "p-value: 0.2857\n",
      "❌ No significant difference.\n",
      "\n",
      "RL vs Kontrollgruppe\n",
      "Test used: Mann-Whitney U\n",
      "p-value: nan\n",
      "❌ No significant difference.\n",
      "\n",
      "VR vs RL\n",
      "Test used: Mann-Whitney U\n",
      "p-value: nan\n",
      "❌ No significant difference.\n",
      "\n",
      "\n",
      "--- Analyzing Slope ---\n",
      "\n",
      "VR vs Kontrollgruppe\n",
      "Test used: Mann-Whitney U\n",
      "p-value: 0.4286\n",
      "❌ No significant difference.\n",
      "\n",
      "RL vs Kontrollgruppe\n",
      "Test used: Independent t-test\n",
      "p-value: 0.0400\n",
      "✅ Significant difference!\n",
      "\n",
      "VR vs RL\n",
      "Test used: Mann-Whitney U\n",
      "p-value: 0.0736\n",
      "❌ No significant difference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/_sqg2_l97_541t3dyx02t65w0000gn/T/ipykernel_40191/3413709677.py:20: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  p_norm1 = stats.shapiro(data1)[1]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Table",
   "id": "2cb7c54f66cc373"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Metrics you want to report\n",
    "metrics = ['Improvement_%', 'Slope']\n",
    "\n",
    "# Create empty list to collect rows\n",
    "summary_data = []\n",
    "\n",
    "# Loop through each group\n",
    "for group in df_pivot['Group'].unique():\n",
    "    row = {'Gruppe': group}\n",
    "\n",
    "    for metric in metrics:\n",
    "        group_data = df_pivot[df_pivot['Group'] == group][metric]\n",
    "\n",
    "        # Remove inf, -inf, and NaN before calculation\n",
    "        group_data_clean = group_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "        mean = group_data_clean.mean()\n",
    "        std = group_data_clean.std()\n",
    "\n",
    "        # Format \"mean ± std\"\n",
    "        row[metric] = f\"{mean:.2f} ± {std:.2f}\"\n",
    "\n",
    "    # Add number of participants (after cleaning inf values if you want)\n",
    "    n_participants = df_pivot[df_pivot['Group'] == group]['ID'].nunique()\n",
    "    row['Anzahl der Teilnehmenden'] = n_participants\n",
    "\n",
    "    summary_data.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Reorder columns nicely\n",
    "summary_df = summary_df[['Gruppe', 'Improvement_%', 'Slope', 'Anzahl der Teilnehmenden']]\n",
    "\n",
    "# Rename columns for nice output\n",
    "summary_df.columns = ['Gruppe', 'Metrik 1 (Improvement %)', 'Metrik 2 (Slope)', 'Anzahl der Teilnehmenden']\n",
    "\n",
    "# Show final table\n",
    "print(summary_df)\n",
    "\n",
    "# save to ./results as csv\n",
    "summary_df.to_csv(f'./results/summary_table_{EXERCISE}.csv', index=False)\n",
    "df_pivot.to_csv(f'./results/df_metrics_{EXERCISE}.csv', index=False)\n"
   ],
   "id": "b6d226fc04ff5757",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4af99fe3f15b10a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
